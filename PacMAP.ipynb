{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for PacMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First for Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualUnit(nn.Module):\n",
    "    def __init__(self, n_filters_in, n_filters_out, kernel_size=17, stride=1, dropout_rate=0.2, \n",
    "                 preactivation=True, postactivation_bn=False, activation_function='relu'):\n",
    "        super(ResidualUnit, self).__init__()\n",
    "        self.preactivation = preactivation\n",
    "        self.postactivation_bn = postactivation_bn\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # Activation function\n",
    "        if activation_function == 'relu':\n",
    "            self.activation = nn.ReLU(inplace=True)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Activation function '{}' not implemented.\".format(activation_function))\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(n_filters_in)\n",
    "        self.conv1 = nn.Conv1d(n_filters_in, n_filters_out, kernel_size, stride=1, padding=kernel_size//2, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(n_filters_out)\n",
    "        self.conv2 = nn.Conv1d(n_filters_out, n_filters_out, kernel_size, stride=stride, padding=kernel_size//2 - 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.downsample = stride != 1 or n_filters_in != n_filters_out\n",
    "        if self.downsample:\n",
    "            self.conv_shortcut = nn.Conv1d(n_filters_in, n_filters_out, 1, stride=stride, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = x\n",
    "        if self.preactivation:\n",
    "            out = self.bn1(out)\n",
    "            out = self.activation(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.activation(out)\n",
    "        if self.dropout_rate > 0:\n",
    "            out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.downsample:\n",
    "            identity = self.conv_shortcut(identity)\n",
    "\n",
    "        out += identity\n",
    "        if not self.preactivation or self.postactivation_bn:\n",
    "            out = self.bn2(out)\n",
    "            out = self.activation(out)\n",
    "        return out\n",
    "\n",
    "class ResNet1DRegression(nn.Module):\n",
    "    def __init__(self, input_length=100, kernel_size=16):\n",
    "        super(ResNet1DRegression, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size, stride=1, padding=kernel_size//2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.res1 = ResidualUnit(64, 128, kernel_size=kernel_size, stride=3)\n",
    "        self.res2 = ResidualUnit(128, 196, kernel_size=kernel_size, stride=3)\n",
    "        self.res3 = ResidualUnit(196, 256, kernel_size=kernel_size, stride=2)\n",
    "        self.res4 = ResidualUnit(256, 320, kernel_size=kernel_size, stride=2)\n",
    "\n",
    "        self.flatten_dim = self._get_flatten_dim(input_length)\n",
    "        self.fc = nn.Linear(self.flatten_dim, 1)\n",
    "\n",
    "    def _get_flatten_dim(self, input_length):\n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros(1, 1, input_length)\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.res1(x)\n",
    "            x = self.res2(x)\n",
    "            x = self.res3(x)\n",
    "            x = self.res4(x)\n",
    "            flatten_dim = x.view(1, -1).size(1)\n",
    "        return flatten_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 1, input_length]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        x = self.res3(x)\n",
    "        x = self.res4(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def get_latent(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        x = self.res3(x)\n",
    "        x = self.res4(x)\n",
    "        latent = x.view(x.size(0), -1)\n",
    "        \n",
    "        return latent\n",
    "\n",
    "def train_age_resnet(device, X, Y, lr=0.001, batch_size=256, num_epoch=16, end_factor=0.1, use_tqdm=True, input_length=100):\n",
    "    model = ResNet1DRegression(input_length=input_length).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer, start_factor=1.0, end_factor=end_factor, total_iters=(num_epoch * len(X)) // batch_size\n",
    "    )\n",
    "    criterion = nn.MSELoss()  # MSE loss for regression\n",
    "    \n",
    "    epoch_iterator = tqdm(range(num_epoch), desc=\"Training Epochs\") if use_tqdm else range(num_epoch)\n",
    "    for epoch in epoch_iterator:\n",
    "        # Shuffle data at each epoch\n",
    "        permutation = np.random.permutation(len(X))\n",
    "        X = X[permutation]\n",
    "        Y = Y[permutation]\n",
    "        \n",
    "        for batch_idx in range(0, len(X), batch_size):\n",
    "            batch_data = X[batch_idx:batch_idx+batch_size]\n",
    "            batch_target = Y[batch_idx:batch_idx+batch_size]\n",
    "            \n",
    "            # Prepare tensors\n",
    "            batch_data = torch.tensor(batch_data, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "            batch_target = torch.tensor(batch_target, dtype=torch.float32).view(-1, 1).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred = model(batch_data)\n",
    "            loss = criterion(pred, batch_target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            epoch_iterator.set_description(f\"Epoch {epoch+1}, loss: {loss.item():.5f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Testing function for the ResNet regression model\n",
    "def test_age_resnet(model, device, X):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(X)):\n",
    "            data = torch.tensor(X[i], dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "            output = model(data)\n",
    "            predictions.append(output.cpu().numpy())\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pacmap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "model = ResNet1DRegression(input_length=100).to(device)\n",
    "# Load the saved state dictionary into the model\n",
    "#fold = random.randint(1, 5)\n",
    "fold=4\n",
    "model.load_state_dict(torch.load(\"ModelOutputNormalized_Resnet/resnet_lr0001_model_state_fold{}.pth\".format(fold)))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "def extract_latent(model, device, X):\n",
    "    model.eval()\n",
    "    latent_list = []\n",
    "    dataset = TensorDataset(torch.tensor(X, dtype=torch.float32).unsqueeze(1))\n",
    "    loader = DataLoader(dataset, batch_size=1024, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x_batch = batch[0].to(device)\n",
    "            latent = model.get_latent(x_batch)\n",
    "            latent_list.append(latent.cpu().numpy())\n",
    "    latent_data = np.concatenate(latent_list, axis=0)\n",
    "    return latent_data\n",
    "\n",
    "    \n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "indices = np.arange(len(X))\n",
    "\n",
    "for fold_idx, (train_val_idx, _) in enumerate(kf.split(indices)):\n",
    "    if (fold_idx + 1) == fold:\n",
    "        train_fold_idx, val_fold_idx = train_test_split(train_val_idx, test_size=0.20, random_state=seed)\n",
    "        X_val_fold = X[val_fold_idx]\n",
    "        break\n",
    "        \n",
    "latent_data = extract_latent(model, device, X_val_fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding = pacmap.PaCMAP(n_components=2, random_state=42)\n",
    "latent_2d = embedding.fit_transform(latent_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=Y[val_fold_idx], cmap='viridis')\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Age', fontsize=20) \n",
    "cbar.ax.tick_params(labelsize=18)\n",
    "plt.xlabel(\"Component 1\", fontsize=20)\n",
    "plt.ylabel(\"Component 2\", fontsize=20)\n",
    "plt.title(f\"PacMAP of ResNet PPG Signal Embeddings\", fontsize=22)\n",
    "plt.xticks([]) \n",
    "plt.yticks([])  \n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig(\"pacmap_resnet.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now for SMoLK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnedFiltersAge(nn.Module):\n",
    "    def __init__(self, num_kernels=24):\n",
    "        super(LearnedFiltersAge, self).__init__()\n",
    "        # 100 point signals so chose 25, 15, 10 instead of 192, 96, 64\n",
    "        self.conv1 = nn.Conv1d(1, num_kernels, kernel_size=100, stride=1, bias=True)\n",
    "        self.conv2 = nn.Conv1d(1, num_kernels, kernel_size=50, stride=1, bias=True)\n",
    "        self.conv3 = nn.Conv1d(1, num_kernels, kernel_size=20, stride=1, bias=True)\n",
    "        \n",
    "        self.linear = nn.Linear(num_kernels*3 + 51, 1)  # 51 instead of 321 for size of power spectrum\n",
    "    \n",
    "    def forward(self, x, powerspectrum):\n",
    "        c1 = F.leaky_relu(self.conv1(x)).mean(dim=-1) # shape of x is [B, 1, 100]\n",
    "        c2 = F.leaky_relu(self.conv2(x)).mean(dim=-1)\n",
    "        c3 = F.leaky_relu(self.conv3(x)).mean(dim=-1)\n",
    "        \n",
    "        aggregate = torch.cat([c1, c2, c3, powerspectrum], dim=1) # shape of powerspectrum is [B, 51]\n",
    "        aggregate = self.linear(aggregate)\n",
    "        \n",
    "        return aggregate\n",
    "    \n",
    "    def get_latent(self, x, powerspectrum):\n",
    "        c1 = F.leaky_relu(self.conv1(x)).mean(dim=-1)\n",
    "        c2 = F.leaky_relu(self.conv2(x)).mean(dim=-1)\n",
    "        c3 = F.leaky_relu(self.conv3(x)).mean(dim=-1)\n",
    "        \n",
    "        # Concatenate to form latent representation\n",
    "        latent = torch.cat([c1, c2, c3, powerspectrum], dim=1)\n",
    "        return latent\n",
    "\n",
    "def train_age(device, X, Y, num_kernels=24, lr=0.001, batch_size=256, num_epoch=16, end_factor=0.1, use_tqdm=True):\n",
    "    # compute power spectra for X\n",
    "    PowerSpectra = []\n",
    "    for i in tqdm(range(0, len(X)), desc=\"Computing Power Spectra\"):\n",
    "        PowerSpectra.append(periodogram(X[i], fs=100)[1])\n",
    "    PowerSpectra = np.float32(PowerSpectra)\n",
    "    \n",
    "    model = LearnedFiltersAge(num_kernels=num_kernels).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer, start_factor=1.0, end_factor=end_factor, total_iters=(num_epoch * len(X)) // batch_size\n",
    "    )\n",
    "    criterion = nn.MSELoss() # MSE Loss instead of CrossEntropy\n",
    "    \n",
    "    epoch_iterator = tqdm(range(num_epoch), desc=\"Training Epochs\") if use_tqdm else range(num_epoch)\n",
    "    for epoch in epoch_iterator:\n",
    "        # Shuffle data at each epoch\n",
    "        permutation = np.random.permutation(len(X))\n",
    "        X = X[permutation]\n",
    "        Y = Y[permutation]\n",
    "        PowerSpectra = PowerSpectra[permutation]\n",
    "        \n",
    "        for batch_idx in range(0, len(X), batch_size):\n",
    "            batch_data = X[batch_idx:batch_idx+batch_size]\n",
    "            batch_power = PowerSpectra[batch_idx:batch_idx+batch_size]\n",
    "            batch_target = Y[batch_idx:batch_idx+batch_size]\n",
    "            \n",
    "            # Prepare tensors\n",
    "            batch_data = torch.tensor(batch_data, dtype=torch.float32).unsqueeze(1).to(device) \n",
    "            batch_power = torch.tensor(batch_power, dtype=torch.float32).to(device)\n",
    "            batch_target = torch.tensor(batch_target, dtype=torch.float32).view(-1, 1).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred = model(batch_data, batch_power)\n",
    "            loss = criterion(pred, batch_target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            epoch_iterator.set_description(f\"Epoch {epoch+1}, loss: {loss.item():.5f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def test_age(model, device, X):\n",
    "    # compute power spectra for X\n",
    "    PowerSpectra = []\n",
    "    for i in range(len(X)):\n",
    "        PowerSpectra.append(periodogram(X[i], fs=100)[1])\n",
    "    PowerSpectra = np.stack(PowerSpectra)\n",
    "    \n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X)):\n",
    "            data = torch.tensor(X[i], dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device) \n",
    "            powerspectrum = torch.tensor(PowerSpectra[i], dtype=torch.float32).unsqueeze(0).to(device) \n",
    "            output = model(data, powerspectrum)\n",
    "            predictions.append(output.cpu().numpy())\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pacmap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "model = LearnedFiltersAge(num_kernels=384).to(device)\n",
    "# Load the saved state dictionary into the model\n",
    "#fold = random.randint(1, 5)\n",
    "fold = 4\n",
    "model.load_state_dict(torch.load(\"ModelOutputNormalized/smolk_model_lr0001_384_200_fold{}.pth\".format(fold)))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import KFold, train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_latent_smolk(model, device, X, fs=100, batch_size=1024):\n",
    "    # Compute power spectra for each sample in X.\n",
    "    power_spectra = []\n",
    "    for i in tqdm(range(len(X)), desc=\"Computing Power Spectra for Latent Extraction\"):\n",
    "        # periodogram returns (freqs, power), and here we take the power spectrum.\n",
    "        power_spectra.append(periodogram(X[i], fs=fs)[1])\n",
    "    power_spectra = np.array(power_spectra).astype(np.float32)\n",
    "    \n",
    "    # Create a dataset with both the raw signal and its corresponding power spectrum.\n",
    "    # Expected shapes: X -> [N, signal_length] and power_spectra -> [N, 51] (or however many bins you obtain)\n",
    "    dataset = TensorDataset(\n",
    "        torch.tensor(X, dtype=torch.float32).unsqueeze(1),   # Add channel dimension: [N, 1, signal_length]\n",
    "        torch.tensor(power_spectra, dtype=torch.float32)\n",
    "    )\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    latent_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x_batch, power_batch = batch\n",
    "            x_batch = x_batch.to(device)\n",
    "            power_batch = power_batch.to(device)\n",
    "            # Use the get_latent method to extract the representation\n",
    "            latent = model.get_latent(x_batch, power_batch)\n",
    "            latent_list.append(latent.cpu().numpy())\n",
    "    \n",
    "    latent_data = np.concatenate(latent_list, axis=0)\n",
    "    return latent_data\n",
    "\n",
    "def visualize_latent_with_pacmap(latent_data, labels=None):\n",
    "    embedding = pacmap.PaCMAP(n_components=2, random_state=42)\n",
    "    latent_2d = embedding.fit_transform(latent_data)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if labels is not None:\n",
    "        scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=labels, cmap='viridis')\n",
    "        plt.colorbar(scatter, label='Age')\n",
    "    else:\n",
    "        plt.scatter(latent_2d[:, 0], latent_2d[:, 1], cmap='viridis')\n",
    "    plt.xlabel(\"Component 1\")\n",
    "    plt.ylabel(\"Component 2\")\n",
    "    plt.title(\"Latent Space Embedding via PaCMAP\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "indices = np.arange(len(X))\n",
    "\n",
    "for fold_idx, (train_val_idx, _) in enumerate(kf.split(indices)):\n",
    "    if (fold_idx + 1) == fold:\n",
    "        train_fold_idx, val_fold_idx = train_test_split(train_val_idx, test_size=0.20, random_state=seed)\n",
    "        X_val_fold = X[val_fold_idx]\n",
    "        break\n",
    "\n",
    "latent_data = extract_latent_smolk(model, device, X_val_fold)\n",
    "visualize_latent_with_pacmap(latent_data, labels=Y[val_fold_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = pacmap.PaCMAP(n_components=2, random_state=42)\n",
    "latent_2d = embedding.fit_transform(latent_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=Y[val_fold_idx], cmap='viridis')\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Age', fontsize=26) \n",
    "cbar.ax.tick_params(labelsize=22)\n",
    "plt.xlabel(\"Component 1\", fontsize=26)\n",
    "plt.ylabel(\"Component 2\", fontsize=26)\n",
    "plt.title(f\"PacMAP of SMoLK PPG Embeddings\", fontsize=28)\n",
    "plt.xticks([]) \n",
    "plt.yticks([])  \n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig(\"pacmap_smolk.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
